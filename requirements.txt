# Core dependencies - tested with Python 3.11-3.12
httpx[http2]>=0.27.0,<0.28.0
pydantic>=2.0.0,<3.0.0
psutil>=5.9.0,<6.0.0

# Optional dependencies for extended functionality
# Install with: pip install -r requirements.txt && pip install llama-cpp-python pynvml

# llama-cpp-python>=0.2.0  # For llama.cpp provider (GGUF models)
# pynvml>=11.5.0           # For NVIDIA GPU monitoring
